{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCinREJNFNz36c68lQL22A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6henrykim/NLP-Portfolio/blob/main/wordnet/homework3_htk180000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3: WordNet\n",
        "\n",
        "CS 4395.002 Human Language Technologies\n",
        "\n",
        "Dr. Mazidi\n",
        "\n",
        "Henry Kim HTK180000\n",
        "\n",
        "## 1. WordNet Summary\n",
        "[WordNet](https://wordnet.princeton.edu/) is database of English words maintained by Princeton University that organizes each word into synsets based on its different defintions. It can be used to find words that have a similar meaning, words of the same meaning that are more specific, or words of the same meaning that are less specific.\n",
        "\n",
        "Princeton University \"About WordNet.\" WordNet. Princeton University. 2010. "
      ],
      "metadata": {
        "id": "bbGu-oyhRkCN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p3G6liXRfpx"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import math\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "# Download nltk data\n",
        "nltk.download('all')\n",
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Noun Synsets\n",
        "Here are the synsets of the word 'light'"
      ],
      "metadata": {
        "id": "OpKMbSMskoAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for synset in wn.synsets('light'):\n",
        "  print(synset)\n",
        "  print('\\t' + synset.name())\n",
        "  print('\\t' + synset.definition())"
      ],
      "metadata": {
        "id": "sPZqiefsk4G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fc9083-a55c-45e1-8941-3b1a04f0dee1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('light.n.01')\n",
            "\tlight.n.01\n",
            "\t(physics) electromagnetic radiation that can produce a visual sensation\n",
            "Synset('light.n.02')\n",
            "\tlight.n.02\n",
            "\tany device serving as a source of illumination\n",
            "Synset('light.n.03')\n",
            "\tlight.n.03\n",
            "\ta particular perspective or aspect of a situation\n",
            "Synset('luminosity.n.01')\n",
            "\tluminosity.n.01\n",
            "\tthe quality of being luminous; emitting or reflecting light\n",
            "Synset('light.n.05')\n",
            "\tlight.n.05\n",
            "\tan illuminated area\n",
            "Synset('light.n.06')\n",
            "\tlight.n.06\n",
            "\ta condition of spiritual awareness; divine illumination\n",
            "Synset('light.n.07')\n",
            "\tlight.n.07\n",
            "\tthe visual effect of illumination on objects or scenes as created in pictures\n",
            "Synset('light.n.08')\n",
            "\tlight.n.08\n",
            "\ta person regarded very fondly\n",
            "Synset('light.n.09')\n",
            "\tlight.n.09\n",
            "\thaving abundant light or illumination\n",
            "Synset('light.n.10')\n",
            "\tlight.n.10\n",
            "\tmental understanding as an enlightening experience\n",
            "Synset('sparkle.n.01')\n",
            "\tsparkle.n.01\n",
            "\tmerriment expressed by a brightness or gleam or animation of countenance\n",
            "Synset('light.n.12')\n",
            "\tlight.n.12\n",
            "\tpublic awareness\n",
            "Synset('inner_light.n.01')\n",
            "\tinner_light.n.01\n",
            "\ta divine presence believed by Quakers to enlighten and guide the soul\n",
            "Synset('light.n.14')\n",
            "\tlight.n.14\n",
            "\ta visual warning signal\n",
            "Synset('lighter.n.02')\n",
            "\tlighter.n.02\n",
            "\ta device for lighting or igniting fuel or charges or fires\n",
            "Synset('light.v.01')\n",
            "\tlight.v.01\n",
            "\tmake lighter or brighter\n",
            "Synset('light_up.v.05')\n",
            "\tlight_up.v.05\n",
            "\tbegin to smoke\n",
            "Synset('alight.v.01')\n",
            "\talight.v.01\n",
            "\tto come to rest, settle\n",
            "Synset('ignite.v.01')\n",
            "\tignite.v.01\n",
            "\tcause to start burning; subject to fire or great heat\n",
            "Synset('fall.v.20')\n",
            "\tfall.v.20\n",
            "\tfall to somebody by assignment or lot\n",
            "Synset('unhorse.v.01')\n",
            "\tunhorse.v.01\n",
            "\talight from (a horse)\n",
            "Synset('light.a.01')\n",
            "\tlight.a.01\n",
            "\tof comparatively little physical weight or density\n",
            "Synset('light.a.02')\n",
            "\tlight.a.02\n",
            "\t(used of color) having a relatively small amount of coloring agent\n",
            "Synset('light.a.03')\n",
            "\tlight.a.03\n",
            "\tof the military or industry; using (or being) relatively small or light arms or equipment\n",
            "Synset('light.a.04')\n",
            "\tlight.a.04\n",
            "\tnot great in degree or quantity or number\n",
            "Synset('light.a.05')\n",
            "\tlight.a.05\n",
            "\tpsychologically light; especially free from sadness or troubles\n",
            "Synset('light.a.06')\n",
            "\tlight.a.06\n",
            "\tcharacterized by or emitting light\n",
            "Synset('unaccented.s.02')\n",
            "\tunaccented.s.02\n",
            "\t(used of vowels or syllables) pronounced with little or no stress\n",
            "Synset('light.s.08')\n",
            "\tlight.s.08\n",
            "\teasily assimilated in the alimentary canal; not rich or heavily seasoned\n",
            "Synset('light.s.09')\n",
            "\tlight.s.09\n",
            "\t(used of soil) loose and large-grained in consistency\n",
            "Synset('clean.s.03')\n",
            "\tclean.s.03\n",
            "\t(of sound or color) free from anything that dulls or dims\n",
            "Synset('light.s.11')\n",
            "\tlight.s.11\n",
            "\tmoving easily and quickly; nimble\n",
            "Synset('light.s.12')\n",
            "\tlight.s.12\n",
            "\tdemanding little effort; not burdensome\n",
            "Synset('light.a.13')\n",
            "\tlight.a.13\n",
            "\tof little intensity or power or force\n",
            "Synset('light.a.14')\n",
            "\tlight.a.14\n",
            "\t(physics, chemistry) not having atomic weight greater than average\n",
            "Synset('faint.s.04')\n",
            "\tfaint.s.04\n",
            "\tweak and likely to lose consciousness\n",
            "Synset('light.s.16')\n",
            "\tlight.s.16\n",
            "\tvery thin and insubstantial\n",
            "Synset('abstemious.s.02')\n",
            "\tabstemious.s.02\n",
            "\tmarked by temperance in indulgence\n",
            "Synset('light.s.18')\n",
            "\tlight.s.18\n",
            "\tless than the correct or legal or full amount often deliberately so\n",
            "Synset('light.s.19')\n",
            "\tlight.s.19\n",
            "\thaving little importance\n",
            "Synset('light.s.20')\n",
            "\tlight.s.20\n",
            "\tintended primarily as entertainment; not serious or profound\n",
            "Synset('idle.s.04')\n",
            "\tidle.s.04\n",
            "\tsilly or trivial\n",
            "Synset('light.s.22')\n",
            "\tlight.s.22\n",
            "\tdesigned for ease of movement or to carry little weight\n",
            "Synset('light.s.23')\n",
            "\tlight.s.23\n",
            "\thaving relatively few calories\n",
            "Synset('light.s.24')\n",
            "\tlight.s.24\n",
            "\t(of sleep) easily disturbed\n",
            "Synset('easy.s.10')\n",
            "\teasy.s.10\n",
            "\tcasual and unrestrained in sexual behavior\n",
            "Synset('lightly.r.02')\n",
            "\tlightly.r.02\n",
            "\twith few burdens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Noun Definition, Usage, and Lemmas\n",
        "Let's look at the first synset definition and usage"
      ],
      "metadata": {
        "id": "o0-bVM4Tk4hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noun = wn.synset('light.n.01')\n",
        "print(\"Definition:\") \n",
        "print('\\t' + noun.definition())\n",
        "\n",
        "print(\"Usages:\")\n",
        "for example in noun.examples():\n",
        "  print('\\t' + example)\n",
        "\n",
        "print(\"Lemmas:\")\n",
        "for lemma in noun.lemmas():\n",
        "  print('\\t' + str(lemma))"
      ],
      "metadata": {
        "id": "mfPP00NzlIsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c72cb56-ceeb-4ef2-af0f-97e3428d4a14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition:\n",
            "\t(physics) electromagnetic radiation that can produce a visual sensation\n",
            "Usages:\n",
            "\tthe light was filtered through a soft glass window\n",
            "Lemmas:\n",
            "\tLemma('light.n.01.light')\n",
            "\tLemma('light.n.01.visible_light')\n",
            "\tLemma('light.n.01.visible_radiation')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we traverse up the hierarchy of hypernyms of 'light' according to its first definition. A hypernym of a word is a more abstract or general version of it. The hierarchy goes from more specific nouns at the bottom to more general at the top of the hypernyms, and it ends with the broad category an 'entity' that may or may not even exist at the root. "
      ],
      "metadata": {
        "id": "d5EBk5MMG-hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyp = noun.hypernyms()[0]\n",
        "top = noun.root_hypernyms()\n",
        "\n",
        "while hyp:\n",
        "    print(hyp)\n",
        "    print('\\t' + hyp.name())\n",
        "    print('\\t' + hyp.definition())\n",
        "    if hyp in top:\n",
        "        break\n",
        "    if hyp.hypernyms():\n",
        "        hyp = hyp.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2ldItZmM5y8",
        "outputId": "158b79d5-b42e-4564-9b0d-54c2df5a5b6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('actinic_radiation.n.01')\n",
            "\tactinic_radiation.n.01\n",
            "\telectromagnetic radiation that can produce photochemical reactions\n",
            "Synset('electromagnetic_radiation.n.01')\n",
            "\telectromagnetic_radiation.n.01\n",
            "\tradiation consisting of waves of energy associated with electric and magnetic fields resulting from the acceleration of an electric charge\n",
            "Synset('radiation.n.01')\n",
            "\tradiation.n.01\n",
            "\tenergy that is radiated or transmitted in the form of rays or waves or particles\n",
            "Synset('energy.n.01')\n",
            "\tenergy.n.01\n",
            "\t(physics) a thermodynamic quantity equivalent to the capacity of a physical system to do work; the units of energy are joules or ergs\n",
            "Synset('physical_phenomenon.n.01')\n",
            "\tphysical_phenomenon.n.01\n",
            "\ta natural phenomenon involving the physical properties of matter and energy\n",
            "Synset('natural_phenomenon.n.01')\n",
            "\tnatural_phenomenon.n.01\n",
            "\tall phenomena that are not artificial\n",
            "Synset('phenomenon.n.01')\n",
            "\tphenomenon.n.01\n",
            "\tany state or process known through the senses rather than by intuition or reasoning\n",
            "Synset('process.n.06')\n",
            "\tprocess.n.06\n",
            "\ta sustained phenomenon or one marked by gradual changes through a series of states\n",
            "Synset('physical_entity.n.01')\n",
            "\tphysical_entity.n.01\n",
            "\tan entity that has physical existence\n",
            "Synset('entity.n.01')\n",
            "\tentity.n.01\n",
            "\tthat which is perceived or known or inferred to have its own distinct existence (living or nonliving)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Hypernyms, Hyponyms, Meronyms, Holonyms, and Antonyms\n",
        "Along with hypernyms, WordNet also includes hyponyms (word that is more specific than the base word), meronyms (word that makes up part of the base word), holonnyms (word that base word makes up a part of), and antonyms (word with opposite meaning of base word) for some words."
      ],
      "metadata": {
        "id": "3-ltyGenlk0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hypernyms:\")\n",
        "for hyp in noun.hypernyms():\n",
        "  print('\\t' + str(hyp))\n",
        "\n",
        "print(\"Hyponyms:\")\n",
        "for hyp in noun.hyponyms():\n",
        "  print('\\t' + str(hyp))\n",
        "\n",
        "print(\"Part Meronyms:\")\n",
        "for mer in noun.part_meronyms():\n",
        "  print('\\t' + str(mer))\n",
        "\n",
        "print(\"Substance Meronyms:\")\n",
        "for mer in noun.substance_meronyms():\n",
        "  print('\\t' + str(mer))\n",
        "\n",
        "print(\"Part Holonyms:\")\n",
        "for mer in noun.part_holonyms():\n",
        "  print('\\t' + str(mer))\n",
        "  \n",
        "print(\"Substance Holonyms:\")\n",
        "for mer in noun.substance_holonyms():\n",
        "  print('\\t' + str(mer))\n",
        "\n",
        "antonyms = []\n",
        "for lemma in noun.lemmas():\n",
        "  antonyms += lemma.antonyms()\n",
        "\n",
        "print(\"Antonyms:\")\n",
        "for ant in antonyms:\n",
        "  print('\\t' + ant)"
      ],
      "metadata": {
        "id": "oV8QIv5olze6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10097b50-6a3c-4e62-d6b4-76983348cd71"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hypernyms:\n",
            "\tSynset('actinic_radiation.n.01')\n",
            "Hyponyms:\n",
            "\tSynset('beam.n.04')\n",
            "\tSynset('candlelight.n.01')\n",
            "\tSynset('corona.n.04')\n",
            "\tSynset('counterglow.n.01')\n",
            "\tSynset('daylight.n.02')\n",
            "\tSynset('firelight.n.01')\n",
            "\tSynset('fluorescence.n.01')\n",
            "\tSynset('friar's_lantern.n.01')\n",
            "\tSynset('gaslight.n.01')\n",
            "\tSynset('glow.n.05')\n",
            "\tSynset('half-light.n.01')\n",
            "\tSynset('incandescence.n.01')\n",
            "\tSynset('lamplight.n.01')\n",
            "\tSynset('luminescence.n.01')\n",
            "\tSynset('meteor.n.02')\n",
            "\tSynset('moonlight.n.01')\n",
            "\tSynset('radiance.n.01')\n",
            "\tSynset('scintillation.n.01')\n",
            "\tSynset('starlight.n.01')\n",
            "\tSynset('streamer.n.01')\n",
            "\tSynset('sunlight.n.01')\n",
            "\tSynset('torchlight.n.01')\n",
            "\tSynset('twilight.n.02')\n",
            "Part Meronyms:\n",
            "Substance Meronyms:\n",
            "Part Holonyms:\n",
            "\tSynset('electromagnetic_spectrum.n.01')\n",
            "Substance Holonyms:\n",
            "Antonyms:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Verb Synsets\n",
        "Here are the synsets for the word 'sail.'"
      ],
      "metadata": {
        "id": "5ivgLMoPlzqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for synset in wn.synsets('sail'):\n",
        "  print(synset)\n",
        "  print('\\t' + synset.name())\n",
        "  print('\\t' + synset.definition())"
      ],
      "metadata": {
        "id": "9Rk6eHmhl2yM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db23584a-c798-4e02-81b1-ca79b737be39"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('sail.n.01')\n",
            "\tsail.n.01\n",
            "\ta large piece of fabric (usually canvas fabric) by means of which wind is used to propel a sailing vessel\n",
            "Synset('cruise.n.01')\n",
            "\tcruise.n.01\n",
            "\tan ocean trip taken for pleasure\n",
            "Synset('sail.n.03')\n",
            "\tsail.n.03\n",
            "\tany structure that resembles a sail\n",
            "Synset('sail.v.01')\n",
            "\tsail.v.01\n",
            "\ttraverse or travel on (a body of water)\n",
            "Synset('sweep.v.02')\n",
            "\tsweep.v.02\n",
            "\tmove with sweeping, effortless, gliding motions\n",
            "Synset('sail.v.03')\n",
            "\tsail.v.03\n",
            "\ttravel on water propelled by wind\n",
            "Synset('voyage.v.01')\n",
            "\tvoyage.v.01\n",
            "\ttravel on water propelled by wind or by other means\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Verb Definition, Usage, and Lemmas"
      ],
      "metadata": {
        "id": "HRqZU8Q0l2-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verb = wn.synset('sail.v.01')\n",
        "print(\"Definition:\") \n",
        "print('\\t' + verb.definition())\n",
        "\n",
        "print(\"Usages:\")\n",
        "for example in verb.examples():\n",
        "  print('\\t' + example)\n",
        "\n",
        "print(\"Lemmas:\")\n",
        "for lemma in verb.lemmas():\n",
        "  print('\\t' + str(lemma))"
      ],
      "metadata": {
        "id": "Vh0NH6OKl-LQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e0bcf1-5936-4daa-ae29-ce6ccce15964"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition:\n",
            "\ttraverse or travel on (a body of water)\n",
            "Usages:\n",
            "\tWe sailed the Atlantic\n",
            "\tHe sailed the Pacific all alone\n",
            "Lemmas:\n",
            "\tLemma('sail.v.01.sail')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we traverse up the hierarchy of hypernyms of 'sail' according to its first verb definition. Like with nouns, the hierarchy of verbs starts more specific at the bottom and and more general at the top. Here the verb gets more general in 'travel' to mean traveling in general as opposed to just travel be sea. It then gets even more general to include traveling even in a metaphorical sense."
      ],
      "metadata": {
        "id": "Sp79D9UBMNhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyp = verb.hypernyms()[0]\n",
        "top = verb.root_hypernyms()\n",
        "\n",
        "while hyp:\n",
        "    print(hyp)\n",
        "    print('\\t' + hyp.name())\n",
        "    print('\\t' + hyp.definition())\n",
        "    if hyp in top:\n",
        "        break\n",
        "    if hyp.hypernyms():\n",
        "        hyp = hyp.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMKbjfxfMNvV",
        "outputId": "bf98e177-b5fd-4c13-aff2-c8ff4364247c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('travel.v.04')\n",
            "\ttravel.v.04\n",
            "\ttravel upon or across\n",
            "Synset('travel.v.01')\n",
            "\ttravel.v.01\n",
            "\tchange location; move, travel, or proceed, also metaphorically\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Different Forms\n",
        "Here are different forms of the word 'sail' according to morphy. Since it is rules-based, its capabilities are limited."
      ],
      "metadata": {
        "id": "k3W1e99Rl-gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.morphy('sailor'))\n",
        "print(wn.morphy('sailor'), wn.ADJ)\n",
        "print(wn.morphy('sailor'), wn.VERB)\n",
        "print(wn.morphy('sailor'), wn.NOUN)\n",
        "print(wn.morphy('sailing'))\n",
        "print(wn.morphy('sailing'), wn.ADJ)\n",
        "print(wn.morphy('sailing'), wn.VERB)\n",
        "print(wn.morphy('sailing'), wn.NOUN)\n",
        "print(wn.morphy('sailed'))\n",
        "print(wn.morphy('sailed'), wn.ADJ)\n",
        "print(wn.morphy('sailed'), wn.VERB)\n",
        "print(wn.morphy('sailed'), wn.NOUN)"
      ],
      "metadata": {
        "id": "2TXNnH5ZmCwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2e9fd6-c00f-4e87-cfa3-1059687170cd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sailor\n",
            "sailor a\n",
            "sailor v\n",
            "sailor n\n",
            "sailing\n",
            "sailing a\n",
            "sailing v\n",
            "sailing n\n",
            "sail\n",
            "sail a\n",
            "sail v\n",
            "sail n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Word Similarity\n",
        "Let's compare the similarity of words 'lunch' and 'sandwich.' These words can both be found in the context of having a meal, but neither metric rates them as very similar."
      ],
      "metadata": {
        "id": "5-tQyGOnmC6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use lesk to pick the definitions where the context of the words overlap.\n",
        "context = ['lunch', 'sandwich']\n",
        "word1 = lesk(context, 'lunch')\n",
        "word2 = lesk(context, 'sandwich')\n",
        "\n",
        "print('Path similarity', wn.path_similarity(word1, word2))\n",
        "print('Wu-Palmer similarity', wn.wup_similarity(word1, word2))"
      ],
      "metadata": {
        "id": "ecowgHCimFza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd87176-9986-412d-e0b3-6cc2160745ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path similarity 0.09090909090909091\n",
            "Wu-Palmer similarity 0.16666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The synonyms 'carry' and 'hold' are more similar according to both metrics, but Wu-Palmer rates them as more similar."
      ],
      "metadata": {
        "id": "vDzwl5VmwKWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use lesk to pick the definitions where the context of the words overlap.\n",
        "context = ['carry', 'hold']\n",
        "word1 = lesk(context, 'carry')\n",
        "word2 = lesk(context, 'hold')\n",
        "\n",
        "print('Path similarity', wn.path_similarity(word1, word2))\n",
        "print('Wu-Palmer similarity', wn.wup_similarity(word1, word2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_4u_5oZwKka",
        "outputId": "2e598bdd-d80d-4339-bb01-eda3a795793b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path similarity 0.2\n",
            "Wu-Palmer similarity 0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although 'high' and 'low' are antonyms, they are rated as similar likely due to both describing altitude. "
      ],
      "metadata": {
        "id": "J6Y5fBEmx8s4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use lesk to pick the definitions where the context of the words overlap.\n",
        "context = ['high', 'low']\n",
        "word1 = lesk(context, 'high')\n",
        "word2 = lesk(context, 'low')\n",
        "\n",
        "print('Path similarity', wn.path_similarity(word1, word2))\n",
        "print('Wu-Palmer similarity', wn.wup_similarity(word1, word2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rgc5xFFx83h",
        "outputId": "74327310-f9c3-48ef-d553-03f99db24519"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path similarity 0.25\n",
            "Wu-Palmer similarity 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. SentiWordNet\n",
        "\n",
        "SentiWordNet enhances WordNet by providing data about emotional connotation for each synset in the form of positive, negative, and objective scores. These can be used for evaluating the emotional content of text such as determining if an article is written to evoke a strongly negative reaction in readers to encourage its spread rather than providing objective truth. For example, the word 'fear' has mostly negative emotional connotations and implies there could be danger that requires action."
      ],
      "metadata": {
        "id": "dlp5JD-vmGEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "senti_list = list(swn.senti_synsets('fear')) \n",
        "for item in senti_list:\n",
        "    print(item)\n",
        "    print('\\tPositive score:', item.pos_score())\n",
        "    print('\\tNegative score:', item.neg_score())\n",
        "    print('\\tObjective score:', item.obj_score())"
      ],
      "metadata": {
        "id": "lrQDbYwXmKUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8a6391-24e8-4c9d-daf4-9502f43851c4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<fear.n.01: PosScore=0.0 NegScore=0.875>\n",
            "\tPositive score: 0.0\n",
            "\tNegative score: 0.875\n",
            "\tObjective score: 0.125\n",
            "<concern.n.02: PosScore=0.125 NegScore=0.75>\n",
            "\tPositive score: 0.125\n",
            "\tNegative score: 0.75\n",
            "\tObjective score: 0.125\n",
            "<fear.n.03: PosScore=0.5 NegScore=0.0>\n",
            "\tPositive score: 0.5\n",
            "\tNegative score: 0.0\n",
            "\tObjective score: 0.5\n",
            "<fear.v.01: PosScore=0.125 NegScore=0.625>\n",
            "\tPositive score: 0.125\n",
            "\tNegative score: 0.625\n",
            "\tObjective score: 0.25\n",
            "<fear.v.02: PosScore=0.0 NegScore=0.625>\n",
            "\tPositive score: 0.0\n",
            "\tNegative score: 0.625\n",
            "\tObjective score: 0.375\n",
            "<fear.v.03: PosScore=0.0 NegScore=0.5>\n",
            "\tPositive score: 0.0\n",
            "\tNegative score: 0.5\n",
            "\tObjective score: 0.5\n",
            "<fear.v.04: PosScore=0.0 NegScore=0.625>\n",
            "\tPositive score: 0.0\n",
            "\tNegative score: 0.625\n",
            "\tObjective score: 0.375\n",
            "<reverence.v.01: PosScore=0.625 NegScore=0.0>\n",
            "\tPositive score: 0.625\n",
            "\tNegative score: 0.0\n",
            "\tObjective score: 0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When analyzing the sentence 'that smoothie was delicious,' the SentiWordNet gives it an overall positive score. I was surprised that the postivity comes from 'smoothie' and not 'delicious.' Theoretically, this tool could be useful for determining if restaurant reviews were favorable, but care would have to be taken to ensure there is not bias about which product is being reviewed, such as a 'smoothie' being an inherently positive word even if the customer did not actually enjoy it."
      ],
      "metadata": {
        "id": "2GM58UPd9ljF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'That smoothie was delicious.'\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos = 0\n",
        "neg = 0\n",
        "for token in tokens:\n",
        "    print(token)\n",
        "    senti_list = list(swn.senti_synsets(token))     \n",
        "    if senti_list:\n",
        "        syn = senti_list[0]\n",
        "        print(syn)\n",
        "        neg += syn.neg_score()\n",
        "        pos += syn.pos_score()\n",
        "print('Positive total:', pos)\n",
        "print('Negative total:', neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gSNgh7z9hiP",
        "outputId": "5261b294-19b6-4064-830e-5b6176f73130"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That\n",
            "smoothie\n",
            "<smoothie.n.01: PosScore=0.625 NegScore=0.0>\n",
            "was\n",
            "<washington.n.02: PosScore=0.0 NegScore=0.0>\n",
            "delicious\n",
            "<delicious.n.01: PosScore=0.0 NegScore=0.0>\n",
            ".\n",
            "Positive total: 0.625\n",
            "Negative total: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparison, here is an analysis by VADER, which also gives the sentence a postive score."
      ],
      "metadata": {
        "id": "dtU6L-qBF-hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "vs = analyzer.polarity_scores(sentence)\n",
        "print(sentence, '\\n\\t', str(vs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrS_WTkyF-v6",
        "outputId": "e4c27e54-9266-4590-ece2-b3215b66f9a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That smoothie was delicious. \n",
            "\t {'neg': 0.0, 'neu': 0.448, 'pos': 0.552, 'compound': 0.5719}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Collocation\n",
        "A collocation occurs when multiple words appear together to form a new meaning that is different from what combining their standard definitions would yield. For example, a 'paper weight' refers to a small object that keeps paper on a desk and not a weight made of paper. Here are the collocations found in the Inaugural Address corpus of nltk."
      ],
      "metadata": {
        "id": "ELUA5s_xmKmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for colloc in text4.collocation_list():\n",
        "  print(colloc)"
      ],
      "metadata": {
        "id": "LIOkYeiVmPyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b23f94-6cc2-4b8d-8eda-974613d9ed66"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('United', 'States')\n",
            "('fellow', 'citizens')\n",
            "('years', 'ago')\n",
            "('four', 'years')\n",
            "('Federal', 'Government')\n",
            "('General', 'Government')\n",
            "('American', 'people')\n",
            "('Vice', 'President')\n",
            "('God', 'bless')\n",
            "('Chief', 'Justice')\n",
            "('one', 'another')\n",
            "('fellow', 'Americans')\n",
            "('Old', 'World')\n",
            "('Almighty', 'God')\n",
            "('Fellow', 'citizens')\n",
            "('Chief', 'Magistrate')\n",
            "('every', 'citizen')\n",
            "('Indian', 'tribes')\n",
            "('public', 'debt')\n",
            "('foreign', 'nations')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we calculate the mutual information of the collocation 'Vice President' using the formula P(x,y)=[P(x)*P(y)]. We can also calculate the mutual information of 'every' and 'President' to get a baseline comparison. The collocation 'Vice President' has a relatively high mutual information score, which indicates that Vice President occurs more often than random chance would dictate. 'Vice President' is a significant collocation that refers to a specific political position that 'President' and any other adjective would not describe."
      ],
      "metadata": {
        "id": "DZ67dCWhhV-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text4.tokens)\n",
        "vocab = len(set(text4))\n",
        "\n",
        "vp = text.count('Vice President') / vocab\n",
        "print(\"p(Vice President) = \", vp)\n",
        "v = text.count('Vice') / vocab\n",
        "print(\"p(Vice) = \", v)\n",
        "p = text.count('President') / vocab\n",
        "print('p(President) = ', p)\n",
        "pmi = math.log2(vp / (v * p))\n",
        "print('pmi = ', pmi)\n",
        "print()\n",
        "\n",
        "ep = text.count('every President') / vocab\n",
        "print(\"p(every President) = \", ep)\n",
        "e = text.count('every') / vocab\n",
        "print(\"p(every) = \", e)\n",
        "print('p(President) = ', p)\n",
        "pmi = math.log2(ep / (e * p))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwWaDBBxhu8W",
        "outputId": "ec6e2c06-4de4-4864-b394-71a389a21b80"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(Vice President) =  0.0017955112219451373\n",
            "p(Vice) =  0.0018952618453865336\n",
            "p(President) =  0.010773067331670824\n",
            "pmi =  6.458424602064904\n",
            "\n",
            "p(every President) =  9.975062344139652e-05\n",
            "p(every) =  0.03291770573566085\n",
            "p(President) =  0.010773067331670824\n",
            "pmi =  -1.8298951001796395\n"
          ]
        }
      ]
    }
  ]
}